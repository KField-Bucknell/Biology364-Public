---
title: "Lab 07"
author: "Outstanding Data Scientist"
date: "28 Feb 2023"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
if (!require(MASS)) install.packages('MASS'); library(MASS)
if (!require(foreign)) install.packages('foreign'); library(foreign)
if (!require(cowplot)) install.packages('cowplot'); library(cowplot)
if (!require(readxl)) install.packages('readxl'); library(readxl)
if (!require(UsingR)) install.packages('UsingR'); library(UsingR)
if (!require(see)) install.packages('see'); library(see)
if (!require(performance)) install.packages('performance'); library(performance)
if (!require(interactions)) install.packages('interactions'); library(interactions)
if (!require(broom.mixed)) install.packages('broom.mixed'); library(broom.mixed) # needed by jtools
if (!require(jtools)) install.packages('jtools'); library(jtools)
if (!require(skimr)) install.packages('skimr'); library(skimr)
if (!require(tidyverse)) install.packages('tidyverse'); library(tidyverse)
```

Note that I loaded quite a few new packages. 
These packages, like `performance` and `interactions` are useful for advanced model selection and might be worth exploring on your own.
The `jtools` package provides plot_summs(), a better way to vizulize the coefficients of a model.
The `skimr` package is a great tool for peeking at your data during exploration.
The package `MASS` is essential for `glm.nb()`. 
The package `foreign` is needed to read in the .dta file.

## Background

School administrators study the attendance behavior of high school juniors at two schools. Predictors of the number of days of absence include the type of program in which the student is enrolled and a standardized test in math.

We have attendance data on 314 high school juniors from two urban high schools in the file nb_data. The response variable of interest is days absent, daysabs. The variable math gives the standardized math score for each student. The variable prog is a three-level nominal variable indicating the type of instructional program in which the student is enrolled.

## Data Loading and Wrangling

Load in the data and then convert the appropriate columns to factors.

```{r}
original.dat <- read.dta("https://stats.idre.ucla.edu/stat/stata/dae/nb_data.dta")
dat <- original.dat %>%
    mutate(prog = factor(prog, levels = 1:3, labels = c("General", "Academic", "Vocational")),
           id = as.character(id))
# Some different summary functions
summary(dat)
glimpse(dat)
skim(dat)
```

## Data Exploration

Generate histograms to show daysab for all programs and then for each academic program separately. 

```{r}
ggplot(dat, aes(daysabs, fill = prog)) + 
  geom_histogram(binwidth = 1) + 
  facet_grid(prog ~ ., margins = TRUE, scales = "free") +
  theme_minimal_grid()
```

## Possible statistical models

Below is a list of some analysis methods you may have encountered. Some of the methods listed are quite reasonable, while others have either fallen out of favor or have limitations.

- Negative binomial regression -Negative binomial regression can be used for over-dispersed count data, that is when the conditional variance exceeds the conditional mean. It can be considered as a generalization of Poisson regression since it has the same mean structure as Poisson regression and it has an extra parameter to model the over-dispersion. If the conditional distribution of the outcome variable is over-dispersed, the confidence intervals for the Negative binomial regression are likely to be wider as compared to those from a Poisson regression model.
- Poisson regression – Poisson regression is often used for modeling count data. Poisson regression has a number of extensions useful for count models.
- Zero-inflated regression model – Zero-inflated models attempt to account for excess zeros. In other words, two kinds of zeros are thought to exist in the data, “true zeros” and “excess zeros”. Zero-inflated models estimate two equations simultaneously, one for the count model and one for the excess zeros.
- OLS regression – Count outcome variables are sometimes log-transformed and analyzed using OLS regression. Many issues arise with this approach, including loss of data due to undefined values generated by taking the log of zero (which is undefined), as well as the lack of capacity to model the dispersion.

## Negative Binomial GLM

Make a negative binomial glm and check its summary() and performance()

```{r}
m1 <- glm.nb(daysabs ~ math + prog, data = dat)
summary(m1)
performance(m1)
```

Let's compare that model to one without the academic program.

```{r}
m2 <- glm.nb(daysabs ~ math, data = dat)
performance(m2)
anova(m1, m2)
```

Those results indicate that the model with program is significantly better (p = 1.65e-10).

We can visualize the effect sizes and confidence intervals using the plot_summs() function from jtools.

```{r}
plot_summs(m1, m2)
```


Another approach would be to use model selection to confirm the minimal model. 
The stepAIC() function will take a model and iteratively perform model selection in either the backward or forward direction.

```{r}
stepAIC(m1, direction = "backward")
```

It looks like we should keep both math and prog in the model.

## Check for interactions

```{r}
m4 <- glm.nb(daysabs ~ math * prog, data = dat)
compare_performance(m1, m4)
stepAIC(m4, direction = "backward")
```

Once again we arrive at the best model as `daysabs ~ math + prog`.

## Check model assumptions

First use the plot function to see if this model seems to be a reasonable fit to the data.
Let's use a better function than just plot(), try out the check_model() function of `performance`

```{r}
check_model(m1)
```

Clearly the QQ plot demonstrates that the data is NOT normally distributed. 
But the other plots don't look too bad. If you compare them to a linear model, it looks better.
And we can use the compare_performance() function to compare the two models.

```{r}
lm <- glm(daysabs ~ math, data = dat)
check_model(lm)
compare_performance(m1, lm)
```


Negative binomial models assume the conditional means are not equal to the conditional variances. 
This inequality is captured by estimating a dispersion parameter (not shown in the output) that is held constant in a Poisson model. 
Thus, the Poisson model is actually nested in the negative binomial model. 
We can then use a likelihood ratio test to compare these two and test this model assumption. 
To do this, compare our nb model to a Poisson model (family = "poisson").

To compare the two models, unfortunately we can't use anova() which requires both models to use the same glm function. 
Instead we can use performance to see which model appears to have better information statistics.

```{r}
m3 <- glm(daysabs ~ math + prog, family = "poisson", data = dat)
compare_performance(m1, m3)
```

## Model Visualization

For assistance in further understanding the model, we can look at predicted counts for various levels of our predictors. 
Below we create new datasets with values of math and prog and then use the predict() function to calculate the predicted number of events.

First, we can look at predicted counts for each value of prog while holding math at its mean. 
To do this, we create a new dataset with the combinations of prog and math for which we would like to find predicted values, then use the predict command.

```{r}
predicted_data <- data.frame(math = mean(dat$math), 
                       prog = factor(1:3, levels = 1:3, labels = levels(dat$prog)))
predicted_data$phat <- predict(m1, predicted_data, type = "response")
predicted_data
```
In the output above, we see that the predicted number of events (e.g., days absent) for a general program is about 10.24, holding math at its mean. 
The predicted number of events for an academic program is lower at 6.59, and the predicted number of events for a vocational program is about 2.85.

Below we will obtain the mean predicted number of events for values of math across its entire range for each level of prog and graph these.

## Interaction Plots

```{r}
interact_plot(m1, pred = math,
              modx= prog,  
              interval = TRUE)
```

The graph shows the expected count across the range of math scores, for each type of program along with 95 percent confidence intervals.
Note that the lines are not straight because this is a log linear model, and what is plotted are the expected values, not the log of the expected values.

## Testing an Interaction

To complete the lab, construct a model that includes gender and an interaction between gender and math score. 
Visualize the model that includes the interaction, using the `mod2` parameter of `interact_plot()`.

```{r}
m5 <- glm.nb(daysabs ~ math * gender + prog, data = dat)
summary(m5)
performance(m5)
interact_plot(m5, pred = math,
              modx= prog,
              mod2 = gender,
              interval = TRUE)
compare_performance(m1, m5)
```

Now use backward model selection to determine if gender is an informative explanatory variable.

```{r}
stepAIC(m5, direction = "backward")
```

And finally, compare the models that include gender to the model that doesn't (m1) and visualize the "best" model.

```{r}
m6 <- glm.nb(daysabs ~ math + gender + prog, data = dat)
summary(m6)
performance(m6)
compare_performance(m1, m5, m6)
plot_summs(m1, m5, m6)
interact_plot(m6, pred = math,
              modx= prog,
              mod2 = gender,
              interval = TRUE)
```

## Bonus graphs

Just to show off some of the other features of interact_plot():

```{r}
interact_plot(m6, pred = math,
              modx= gender,
              mod2 = prog,
              interval = TRUE)
```

```{r}
interact_plot(m6, pred = math,
              modx= gender,
              mod2 = prog,
              interval = TRUE, plot.points = TRUE)
```

Things to consider
- It is not recommended that negative binomial models be applied to small samples.
- One common cause of over-dispersion is excess zeros by an additional data generating process. In this situation, zero-inflated model should be considered.
- If the data generating process does not allow for any 0s (such as the number of days spent in the hospital), then a zero-truncated model may be more appropriate.
- Count data often have an exposure variable, which indicates the number of times the event could have happened. This variable should be incorporated into your negative binomial regression model with the use of the offset option. See the glm documentation for details.
- The outcome variable in a negative binomial regression cannot have negative numbers.


# Acknowledgements

Adapted from https://stats.oarc.ucla.edu/r/dae/negative-binomial-regression/
