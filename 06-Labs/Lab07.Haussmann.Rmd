---
title: "Lab 07"
author: "Outstanding Data Scientist"
date: "01 Mar 2023"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
if (!require(MASS)) install.packages('MASS'); library(MASS)
if (!require(foreign)) install.packages('foreign'); library(foreign)
if (!require(cowplot)) install.packages('cowplot'); library(cowplot)
if (!require(readxl)) install.packages('readxl'); library(readxl)
if (!require(UsingR)) install.packages('UsingR'); library(UsingR)
if (!require(see)) install.packages('see'); library(see)
if (!require(performance)) install.packages('performance'); library(performance)
if (!require(interactions)) install.packages('interactions'); library(interactions)
if (!require(broom.mixed)) install.packages('broom.mixed'); library(broom.mixed) # needed by jtools
if (!require(jtools)) install.packages('jtools'); library(jtools)
if (!require(skimr)) install.packages('skimr'); library(skimr)
if (!require(tidyverse)) install.packages('tidyverse'); library(tidyverse)
```

Note that I loaded quite a few new packages. 
These packages, like `performance` and `interactions` are useful for advanced model selection and might be worth exploring on your own.
The `jtools` package provides plot_summs(), a better way to vizulize the coefficients of a model.
The `skimr` package is a great tool for peeking at your data during exploration.
The package `MASS` is essential for `glm.nb()`. 
The package `foreign` is needed to read in the .dta file.

## Background

TRF is dependent. All the rest are independent factors. 

## Data Loading and Wrangling

Load in the data and then convert the appropriate columns to factors.

```{r}
original.dat <- read_excel("MixedEffects KF 2023.03.01.xlsx")
dat <- original.dat %>%
  mutate(Family = as.factor(Family),
         Pen = as.factor(Pen),
         `Wing Band No.` = as.factor(`Wing Band No.`))
# Some different summary functions
summary(dat)
glimpse(dat)
skim(dat)
```

## Data Exploration

Generate histograms. 

```{r}
ggplot(dat, aes(TRF, fill = Family)) + 
  geom_histogram(binwidth = 1) + 
  facet_grid(Family ~ ., margins = TRUE, scales = "free") +
  theme_minimal_grid()
```

```{r}
ggplot(dat, aes(TRF, fill = Pen)) + 
  geom_histogram(binwidth = 1) + 
  facet_grid(Pen ~ ., margins = TRUE, scales = "free") +
  theme_minimal_grid()
```

```{r}
ggplot(dat, aes(TRF, fill = `TRF age`)) + 
  geom_histogram(binwidth = 1) + 
  facet_grid(`TRF age` ~ ., margins = TRUE, scales = "free") +
  theme_minimal_grid()
```

## Possible statistical models

Below is a list of some analysis methods you may have encountered. Some of the methods listed are quite reasonable, while others have either fallen out of favor or have limitations.

- Negative binomial regression -Negative binomial regression can be used for over-dispersed count data, that is when the conditional variance exceeds the conditional mean. It can be considered as a generalization of Poisson regression since it has the same mean structure as Poisson regression and it has an extra parameter to model the over-dispersion. If the conditional distribution of the outcome variable is over-dispersed, the confidence intervals for the Negative binomial regression are likely to be wider as compared to those from a Poisson regression model.
- Poisson regression – Poisson regression is often used for modeling count data. Poisson regression has a number of extensions useful for count models.
- Zero-inflated regression model – Zero-inflated models attempt to account for excess zeros. In other words, two kinds of zeros are thought to exist in the data, “true zeros” and “excess zeros”. Zero-inflated models estimate two equations simultaneously, one for the count model and one for the excess zeros.
- OLS regression – Count outcome variables are sometimes log-transformed and analyzed using OLS regression. Many issues arise with this approach, including loss of data due to undefined values generated by taking the log of zero (which is undefined), as well as the lack of capacity to model the dispersion.

## GLM

Make a glm and check its summary() and performance()

```{r}
m1 <- glm(TRF ~ ., data = dat)
summary(m1)
performance(m1)
```

Another approach would be to use model selection to confirm the minimal model. 
The stepAIC() function will take a model and iteratively perform model selection in either the backward or forward direction.

```{r}
stepAIC(m1, direction = "backward")
```

Selected model: TRF ~ `Wing Band No.` + CORT + `TRF age`


```{r}
m2 <- glm(TRF ~ `Wing Band No.` + CORT + `TRF age`, data = dat)
summary(m2)
performance(m2)
plot_summs(m2)
anova(m1, m2)
anova(m2, m1)
```

Those results indicate that there is essentially no difference in the models (presumably because Family and Pen are fully nested with Wing Band.

We can visualize the effect sizes and confidence intervals using the plot_summs() function from jtools.

```{r}
plot_summs(m1, m2)
```


## Check for interactions

```{r}
m4 <- glm(TRF ~ `Wing Band No.` * CORT * `TRF age`, data = dat)
compare_performance(m1, m4)
stepAIC(m4, direction = "backward")
```

Some of the interactions are kept, although many of the individual factors don't seem to have any statistical power (NA in the coefficient table) 

TRF ~ `Wing Band No.` + CORT + `TRF age` + `Wing Band No.`:CORT + `Wing Band No.`:`TRF age`

```{r}
m5 <- lm(TRF ~ `Wing Band No.` + CORT + `TRF age` + `Wing Band No.`:CORT + `Wing Band No.`:`TRF age`, data = dat)
summary(m5)
```

There is not enough data in the dataset to test all these interactions.

I am going to use m2 moving forward, but it might be worth looking at the interactions further.

## Check model assumptions

First use the plot function to see if this model seems to be a reasonable fit to the data.
Let's use a better function than just plot(), try out the check_model() function of `performance`

```{r}
# check_model(m2) Does not work: Error in data.frame(x = fitted_, y = res_) : arguments imply differing number of rows: 54, 46
check_autocorrelation(m2)
check_collinearity(m2)
check_outliers(m2)
plot_summs(m2)
plot(m2)
```

I'm not sure why check_model() isn't working. But the data look pretty good with plot(m2).
Although note that 8 observations are being identified as having excessive leverage (but they are not identified as outliers using Cook's).


## Interaction Plots

```{r}
interact_plot(m1, pred = CORT,
              modx= `TRF age`, 
              interval = TRUE)
```
```{r}
interact_plot(m1, pred = CORT,
              modx= `TRF age`, 
              interval = TRUE, plot.points = TRUE)
```

Just for fun, I decided to try taking out the ID and using family and pen instead:

```{r}
m6 <- lm(TRF ~ Family + Pen + CORT + `TRF age`, data = dat)
summary(m6)
```

Interesting. 
The effect size is a little smaller and the p value is much higher. 
ID definitely looks like a more important confounder than pen and family together.